# Bug Report - 2026-01-17

## Critical Bugs (P0 - Fix Immediately)

### BUG-001: Background Job Worker Not Implemented
**Severity:** CRITICAL
**Status:** ‚õî Blocking Feature
**Affected Users:** All users using agent conversations

**Description:**
The `jobs` table exists in Supabase and job records are created by the ElevenLabs webhook (`elevenLabsWebhook.ts:96-106`), but there is no worker process to execute these jobs. This means promised features (conversation reports, PDFs) never get generated.

**Location:**
- Job creation: `server/routes/elevenLabsWebhook.ts:96-106`
- Worker: ‚ùå Does not exist

**Evidence:**
```typescript
// Webhook creates job but nothing processes it
const { error: jobError } = await supabaseAdmin.from('jobs').insert({
  type: 'generate_report',
  status: 'pending',
  payload: {
    conversation_id: conversationId,
    transcript: transcript,
    analysis_summary: 'Pending generation'
  }
});
```

**Impact:**
- Users complete agent conversations but receive no follow-up
- Database accumulates pending jobs indefinitely
- User expectations not met (feature appears broken)
- No retry logic or error handling for failed jobs

**Root Cause:**
Implementation incomplete - table schema created but worker not built

**Reproduction Steps:**
1. Complete birth chart analysis
2. Generate symbol
3. Have agent conversation
4. Conversation ends, webhook fires
5. Check `jobs` table ‚Üí Record created with status='pending'
6. Wait indefinitely ‚Üí Status never changes to 'completed'

**Recommended Fix:**
Implement job worker using BullMQ or Inngest:
```typescript
// Pseudocode
const worker = new Worker('reports', async (job) => {
  const { conversation_id, transcript } = job.data;
  const report = await generateReport(transcript);
  await saveReportToDB(conversation_id, report);
});
```

**Priority:** P0 - Blocks advertised functionality

---

### BUG-002: Supabase Stub Fallback Silently Degrades App
**Severity:** CRITICAL
**Status:** ‚õî Silent Failure
**Affected Users:** Any deployment without proper Supabase configuration

**Description:**
When Supabase environment variables are missing or invalid, the app falls back to a stub implementation that returns empty data without visible errors. This makes the app appear to work while actually failing to persist any data.

**Location:** `services/supabaseClient.ts:15-31`

**Evidence:**
```typescript
export const supabase = isConfigured
    ? createClient(supabaseUrl, supabaseAnonKey)
    : {
        // Stub that returns empty data
        auth: {
            signInAnonymously: async () => ({
              data: { user: null },
              error: new Error('Supabase not configured')
            }),
            // ...
        },
        from: () => ({
            upsert: () => Promise.resolve({ error: null }) // ‚ö†Ô∏è Silent success
        })
    } as any;
```

**Impact:**
- User completes entire flow
- No data persists to database
- On refresh, all progress lost
- No visible error message
- Extremely difficult to debug
- Users blame app for "losing" their data

**Example Failure Scenario:**
```
User Journey:
1. Enter birth data ‚úÖ (appears to work)
2. Generate analysis ‚úÖ (appears to work)
3. Generate symbol ‚úÖ (appears to work)
4. Close browser
5. Return later ‚Üí All data gone ‚ùå
6. User thinks app is broken
```

**Root Cause:**
Defensive programming taken too far - stub should fail fast instead of silently degrading

**Recommended Fix:**
Replace stub with immediate error:
```typescript
if (!isConfigured) {
    throw new Error('FATAL: Supabase not configured. Set VITE_SUPABASE_URL and VITE_SUPABASE_ANON_KEY');
}

export const supabase = createClient(supabaseUrl, supabaseAnonKey);
```

Or show error UI:
```tsx
if (!isConfigured) {
  return <ErrorBoundary message="Database not configured. Contact support." />;
}
```

**Priority:** P0 - Data loss risk

---

### BUG-003: No Rate Limiting on Expensive API Endpoints
**Severity:** HIGH
**Status:** üö® Security/Cost Risk
**Affected Resources:** Gemini API billing, Database capacity

**Description:**
API endpoints have no rate limiting, allowing unlimited requests. This creates both a cost attack vector (expensive Gemini API calls) and a database flood risk.

**Vulnerable Endpoints:**
```
POST /api/symbol      - $0.02-0.10 per Gemini call
POST /api/analysis    - Database writes + BaziEngine calls
POST /api/agent/session - JWT creation + DB writes
```

**Location:** `server/server.ts` - No rate limiting middleware applied

**Evidence:**
```typescript
// Current: No rate limiting
app.post('/api/symbol', async (req, res) => {
  // Direct to expensive Gemini API
  const response = await ai.models.generateContent({...});
});
```

**Impact:**
- Cost attack: Malicious user repeatedly calls `/api/symbol` ‚Üí Runaway Gemini API costs
- Database flood: Spam requests ‚Üí Database capacity exhausted
- DoS: Legitimate users blocked by resource exhaustion
- No per-user throttling (even authenticated users)

**Attack Vector Example:**
```bash
# Attacker script
while true; do
  curl -X POST http://app/api/symbol \
    -H "Content-Type: application/json" \
    -d '{"prompt":"test"}' &
done
# Result: Hundreds of parallel Gemini API calls = $$$
```

**Root Cause:**
MVP launched without production hardening

**Recommended Fix:**
Implement express-rate-limit:
```typescript
import rateLimit from 'express-rate-limit';

const symbolRateLimit = rateLimit({
  windowMs: 15 * 60 * 1000, // 15 minutes
  max: 5, // 5 requests per window
  message: 'Too many symbol generation requests, try again later'
});

app.post('/api/symbol', symbolRateLimit, async (req, res) => { ... });
```

**Priority:** P0 - Financial and security risk

---

## High Priority Bugs (P1 - Fix Soon)

### BUG-004: Quiz Data Hardcoded in Production Code
**Severity:** HIGH
**Status:** üîß Maintenance Burden
**Affected Feature:** Quiz system

**Description:**
225 lines of quiz data are hardcoded directly in `services/quizService.ts`. This makes content management impossible without code changes and deployments.

**Location:** `services/quizService.ts:4-145`

**Evidence:**
```typescript
const MOCK_CATEGORIES: Category[] = [
  { id: 'c_perso', name: 'Archetypen & Pers√∂nlichkeit', icon: '‚öúÔ∏è', ... },
  // 3 more categories...
];

const MOCK_QUIZZES: Quiz[] = [
  {
    id: 'p_krafttier',
    categoryId: 'c_perso',
    type: 'PERSONALITY',
    title: 'Welcher uralte W√§chter schlummert in deiner Seele?',
    // 70+ lines of questions, options, and results...
  },
  // More quizzes...
];
```

**Impact:**
- Cannot add/edit quizzes without code deployment
- No A/B testing capability
- No content versioning
- Translating quizzes requires code changes
- Marketing team blocked (needs developer for every change)
- Slows iteration velocity dramatically

**Root Cause:**
MVP shortcut - temporary mock data never replaced

**Recommended Fix:**
Option A - Supabase tables:
```sql
CREATE TABLE quiz_categories (
  id UUID PRIMARY KEY,
  name TEXT,
  icon TEXT,
  description TEXT
);

CREATE TABLE quizzes (
  id UUID PRIMARY KEY,
  category_id UUID REFERENCES quiz_categories,
  type TEXT CHECK (type IN ('TRIVIA', 'PERSONALITY')),
  title TEXT,
  questions JSONB,
  results JSONB
);
```

Option B - CMS integration (Contentful/Sanity)

**Priority:** P1 - Blocks content team

---

### BUG-005: Timezone Fetching Not Implemented
**Severity:** HIGH
**Status:** ‚ö†Ô∏è Incomplete Feature
**Affected Accuracy:** Birth chart calculations

**Description:**
Birth chart accuracy requires correct timezone, but timezone is not fetched from server. App uses browser default which may be incorrect for users traveling or using VPN.

**Location:** `components/InputCard.tsx:80`

**Evidence:**
```typescript
tz: defaultTz // TODO: Fetch from Google Timezone API
```

**Impact:**
- Incorrect timezone = incorrect birth chart calculations
- Affects ascendant, houses, and time-sensitive data
- No validation that user's browser timezone matches birth location
- Coordinates collected but not used for timezone lookup

**Example Failure:**
```
User in California VPN'd to UK
Browser reports: GMT (Europe/London)
Birth location: Los Angeles, CA
Correct timezone: PST/PDT (America/Los_Angeles)
Result: Chart calculated for wrong timezone ‚Üí Incorrect ascendant
```

**Root Cause:**
Feature planned but not implemented (TODO comment)

**Recommended Fix:**
Implement server endpoint:
```typescript
// server/routes/timezone.ts
app.get('/api/timezone', async (req, res) => {
  const { lat, lng, timestamp } = req.query;

  const response = await fetch(
    `https://maps.googleapis.com/maps/api/timezone/json?` +
    `location=${lat},${lng}&timestamp=${timestamp}&key=${GOOGLE_API_KEY}`
  );

  const data = await response.json();
  res.json({ timezone: data.timeZoneId }); // e.g., "America/Los_Angeles"
});
```

Then call from frontend before analysis.

**Priority:** P1 - Affects core feature accuracy

---

### BUG-006: Retrograde Calculations Are Approximations
**Severity:** MEDIUM
**Status:** ‚ö†Ô∏è Accuracy Issue
**Affected Feature:** Transit calculations (Cosmic Weather)

**Description:**
Planetary retrograde status calculated using simplified sine wave approximation instead of proper ephemeris data. Results may be astronomically incorrect.

**Location:** `server/routes/transits.ts:100-109`

**Evidence:**
```typescript
// NOTE: This retrograde flag is a simplified MVP placeholder based on an arbitrary sine threshold.
// For production use, replace with proper ephemeris-based retrograde calculations.
const retroPattern = retrogradePatterns[planet] || { frequency: 180, phase: 0 };
const retroSignal = Math.sin(jd / retroPattern.frequency + retroPattern.phase);
const isRetro = retroSignal < -0.8; // ‚ö†Ô∏è Arbitrary threshold
```

**Impact:**
- Transit display may show incorrect retrograde status
- Users making decisions based on incorrect data
- Reputation risk if astrology community discovers inaccuracy
- Cannot be trusted for professional astrology use

**Root Cause:**
MVP shortcut - proper astronomical calculation complex

**Recommended Fix:**
Integrate Swiss Ephemeris (already in project for tests):
```typescript
import swisseph from 'swisseph';

const getPlanetPosition = (date: Date, planet: string) => {
  const julianDay = getJulianDate(date);
  const flag = swisseph.SEFLG_SWIEPH | swisseph.SEFLG_SPEED;

  const result = swisseph.calc_ut(julianDay, planetId, flag);
  const isRetrograde = result.data[3] < 0; // Speed < 0 = retrograde

  return {
    sign: getZodiacSign(result.data[0]),
    degree: Math.floor(result.data[0] % 30),
    isRetrograde
  };
};
```

**Priority:** P1 - Accuracy critical for trust

---

## Medium Priority Bugs (P2 - Fix Before Scale)

### BUG-007: No Error Monitoring Integration
**Severity:** MEDIUM
**Status:** üìä Observability Gap
**Affected:** All errors

**Description:**
Errors only logged to console. No integration with error tracking service (Sentry, Datadog, Rollbar). Production errors invisible until users report them.

**Location:** All error handling locations

**Evidence:**
```typescript
// Current: Console only
console.error("Failed to save state to Supabase", error);

// No structured error tracking
// No user context attached
// No error grouping/deduplication
// No alerting
```

**Impact:**
- Cannot proactively detect issues
- No error rate trends
- No user impact visibility
- No stack traces in production (minified)
- Slow incident response

**Recommended Fix:**
```typescript
import * as Sentry from '@sentry/node';

Sentry.init({
  dsn: process.env.SENTRY_DSN,
  environment: process.env.NODE_ENV,
  tracesSampleRate: 1.0,
});

// Usage
try {
  await saveState(state);
} catch (error) {
  Sentry.captureException(error, {
    user: { id: userId },
    extra: { state }
  });
  throw error;
}
```

**Priority:** P2 - Critical for production operations

---

### BUG-008: Persistence Tests Incomplete
**Severity:** MEDIUM
**Status:** üß™ Test Coverage Gap
**Affected:** Data persistence reliability

**Description:**
`persistence.test.ts` has explicit TODO for rewriting tests to mock Supabase client for full coverage.

**Location:** `services/persistence.test.ts`

**Evidence:**
```typescript
// TODO: Rewrite tests to mock supabaseClient for full coverage
```

**Impact:**
- Cannot confidently refactor persistence logic
- Regressions may slip through
- Manual testing required for every change
- Blocking other test automation efforts

**Recommended Fix:**
```typescript
import { vi } from 'vitest';
import * as supabaseModule from './supabaseClient';

describe('persistence', () => {
  beforeEach(() => {
    vi.spyOn(supabaseModule, 'supabase', 'get').mockReturnValue({
      auth: {
        getUser: vi.fn().mockResolvedValue({ data: { user: { id: 'test-user' } } })
      },
      from: vi.fn().mockReturnValue({
        select: vi.fn().mockReturnThis(),
        eq: vi.fn().mockReturnThis(),
        single: vi.fn().mockResolvedValue({ data: mockProfile })
      })
    });
  });

  it('should load state from Supabase', async () => {
    const state = await loadState();
    expect(state).toBeDefined();
    expect(state?.analysisResult).toEqual(mockAnalysis);
  });
});
```

**Priority:** P2 - Blocks test automation strategy

---

### BUG-009: No API Caching Strategy
**Severity:** MEDIUM
**Status:** üí∞ Performance/Cost Issue
**Affected:** All API endpoints

**Description:**
No response caching implemented. Same transit request on same day hits calculation logic every time. Wastes compute and increases latency.

**Location:** All API routes

**Evidence:**
```typescript
// Current: Every request recalculates
app.get('/api/transits', (req, res) => {
  const date = req.query.date;
  const transits = calculateLocalTransits(new Date(date));
  res.json({ transits }); // No caching
});
```

**Impact:**
- Unnecessary compute for identical requests
- Higher latency for users
- Increased BaziEngine API costs
- Cannot scale efficiently

**High-Value Cache Opportunities:**
```
GET /api/transits?date=2026-01-17
  ‚Üí Same for ALL users on same day
  ‚Üí Cache key: date
  ‚Üí TTL: 1 hour

POST /api/analysis
  ‚Üí Same birthData = same result
  ‚Üí Cache key: hash(birthData)
  ‚Üí TTL: 24 hours (or forever)
```

**Recommended Fix:**
```typescript
import Redis from 'ioredis';
const redis = new Redis(process.env.REDIS_URL);

app.get('/api/transits', async (req, res) => {
  const cacheKey = `transits:${req.query.date}`;

  const cached = await redis.get(cacheKey);
  if (cached) {
    return res.json(JSON.parse(cached));
  }

  const transits = calculateLocalTransits(new Date(req.query.date));
  await redis.setex(cacheKey, 3600, JSON.stringify(transits)); // 1h TTL

  res.json({ transits });
});
```

**Priority:** P2 - Performance and cost optimization

---

### BUG-010: ElevenLabs Placeholders Accepted
**Severity:** MEDIUM
**Status:** ‚ö†Ô∏è Configuration Issue
**Affected:** Agent conversations

**Description:**
App accepts placeholder agent IDs (e.g., `replace-with-levi-agent-id`) when environment variables not set. Should fail fast with clear setup instructions instead.

**Location:** `services/elevenLabsAgents.ts`

**Evidence:**
```typescript
const PLACEHOLDER_PREFIX = 'replace-with-';
elevenLabsId: import.meta.env.VITE_ELEVENLABS_AGENT_ID_LEVI || `${PLACEHOLDER_PREFIX}levi-agent-id`

// Detection exists but doesn't block app startup
export function isAgentConfigured(agentId: string): boolean {
  const agent = AGENTS.find(a => a.id === agentId);
  return agent ? !agent.elevenLabsId.startsWith(PLACEHOLDER_PREFIX) : false;
}
```

**Impact:**
- App appears to work but agent feature broken
- User sees warning but can still attempt to use feature
- Confusing UX (why show feature if not working?)
- Wastes user time

**Recommended Fix:**
```typescript
// Fail fast on startup
if (
  !import.meta.env.VITE_ELEVENLABS_AGENT_ID_LEVI ||
  !import.meta.env.VITE_ELEVENLABS_AGENT_ID_VICTORIA
) {
  throw new Error(
    'Missing ElevenLabs agent IDs. Set:\n' +
    '  VITE_ELEVENLABS_AGENT_ID_LEVI\n' +
    '  VITE_ELEVENLABS_AGENT_ID_VICTORIA'
  );
}
```

Or hide feature completely in UI if not configured.

**Priority:** P2 - UX clarity

---

## Low Priority Bugs (P3 - Nice to Have)

### BUG-011: No `.env.example` File
**Severity:** LOW
**Status:** üìù Documentation Gap
**Affected:** Developer onboarding

**Description:**
No `.env.example` file makes it difficult for new developers to know which environment variables are required.

**Recommended Fix:**
```bash
# .env.example
# Backend
GEMINI_API_KEY=your_google_gemini_key_here
SUPABASE_URL=https://xxx.supabase.co
SUPABASE_SERVICE_ROLE_KEY=your_service_role_key
SESSION_SECRET=random_32_char_string
ELEVENLABS_TOOL_SECRET=your_elevenlabs_secret
BAZI_ENGINE_URL=https://baziengine-v2.fly.dev

# Frontend
VITE_SUPABASE_URL=https://xxx.supabase.co
VITE_SUPABASE_ANON_KEY=your_anon_key
VITE_ELEVENLABS_AGENT_ID_LEVI=agent_xxx
VITE_ELEVENLABS_AGENT_ID_VICTORIA=agent_xxx
```

**Priority:** P3 - Developer experience

---

### BUG-012: No Database Migration System
**Severity:** LOW
**Status:** üîß Infrastructure Gap
**Affected:** Schema evolution

**Description:**
No migration system for database schema changes. Must manually apply SQL to Supabase dashboard.

**Impact:**
- Error-prone manual schema updates
- No rollback capability
- No schema version tracking
- Difficult to sync dev/staging/prod

**Recommended Fix:**
Implement Supabase migrations:
```bash
npx supabase migration new add_report_column
# Edit migration file
npx supabase migration up
```

**Priority:** P3 - Technical debt

---

## Summary Statistics

| Priority | Count | Total |
|----------|-------|-------|
| P0 (Critical) | 3 bugs | BUG-001, BUG-002, BUG-003 |
| P1 (High) | 3 bugs | BUG-004, BUG-005, BUG-006 |
| P2 (Medium) | 5 bugs | BUG-007 through BUG-010 |
| P3 (Low) | 2 bugs | BUG-011, BUG-012 |
| **Total** | **12 bugs** | |

## Recommended Action Order

1. **BUG-001** - Implement job worker (blocks advertised feature)
2. **BUG-003** - Add rate limiting (financial risk)
3. **BUG-002** - Remove Supabase stub (data loss risk)
4. **BUG-005** - Implement timezone lookup (accuracy)
5. **BUG-004** - Move quizzes to database (unblock content team)
6. **BUG-007** - Add error monitoring (observability)
7. **BUG-006** - Fix retrograde calculations (accuracy)
8. **BUG-009** - Implement caching (performance)
9. **BUG-008** - Complete persistence tests (test coverage)
10. **BUG-010** - Better placeholder handling (UX)
11. **BUG-011** - Add .env.example (documentation)
12. **BUG-012** - Setup migrations (technical debt)
